{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Cross-Model Verification (CMVK)\n",
    "\n",
    "> **Detect hallucinations by comparing outputs across models.**\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand why cross-model verification matters\n",
    "2. Use CMVK to detect drift between outputs\n",
    "3. Compare embeddings and distributions\n",
    "4. Implement multi-model consensus verification\n",
    "5. Set up automatic hallucination detection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Cross-Model Verification?\n",
    "\n",
    "**Problem:** LLMs hallucinate. A single model can confidently output wrong information.\n",
    "\n",
    "**Solution:** If multiple models agree, confidence increases. If they disagree, flag for review.\n",
    "\n",
    "```\n",
    "Single Model:           Cross-Model Verification:\n",
    "\n",
    "  GPT-4                    GPT-4     Claude     Gemini\n",
    "    ‚Üì                        ‚Üì         ‚Üì          ‚Üì\n",
    "\"Paris is the            \"Paris\"   \"Paris\"    \"Paris\"\n",
    " capital of France\"          ‚Üì         ‚Üì          ‚Üì\n",
    "    ‚Üì                      ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  Trust it?                    CONSENSUS: 100%\n",
    "    ü§∑                         ‚úÖ High confidence\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install agent-os[cmvk] --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic Drift Detection\n",
    "\n",
    "Compare two text outputs to measure semantic drift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmvk import verify\n",
    "\n",
    "# Compare two semantically equivalent texts\n",
    "text_a = \"The capital of France is Paris.\"\n",
    "text_b = \"Paris is the capital city of France.\"\n",
    "\n",
    "score = verify(text_a, text_b)\n",
    "\n",
    "print(\"üìä Verification Result\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Text A: {text_a}\")\n",
    "print(f\"Text B: {text_b}\")\n",
    "print(f\"\\nüéØ Drift Score: {score.drift_score:.3f}\")\n",
    "print(f\"   (0.0 = identical, 1.0 = completely different)\")\n",
    "print(f\"\\nüîí Confidence: {score.confidence:.3f}\")\n",
    "print(f\"üìÅ Drift Type: {score.drift_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare semantically different texts\n",
    "text_a = \"The capital of France is Paris.\"\n",
    "text_c = \"The capital of Germany is Berlin.\"\n",
    "\n",
    "score = verify(text_a, text_c)\n",
    "\n",
    "print(\"üìä Different Texts\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Text A: {text_a}\")\n",
    "print(f\"Text C: {text_c}\")\n",
    "print(f\"\\nüéØ Drift Score: {score.drift_score:.3f}\")\n",
    "print(f\"üìÅ Drift Type: {score.drift_type}\")\n",
    "print(f\"\\n‚ö†Ô∏è  High drift detected! Outputs disagree.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Understanding Drift Types\n",
    "\n",
    "CMVK classifies drift into categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmvk import verify, DriftType\n",
    "\n",
    "examples = [\n",
    "    # Semantic drift (meaning changed)\n",
    "    (\"The answer is 42\", \"The answer is 24\", \"SEMANTIC\"),\n",
    "    \n",
    "    # Structural drift (format changed)\n",
    "    (\"Name: John, Age: 30\", \"{\\\"name\\\": \\\"John\\\", \\\"age\\\": 30}\", \"STRUCTURAL\"),\n",
    "    \n",
    "    # Numerical drift (numbers changed)\n",
    "    (\"Revenue: $1,000,000\", \"Revenue: $1,000,001\", \"NUMERICAL\"),\n",
    "    \n",
    "    # Lexical drift (wording changed, meaning same)\n",
    "    (\"The quick brown fox\", \"The fast brown fox\", \"LEXICAL\"),\n",
    "]\n",
    "\n",
    "print(\"üìä Drift Type Examples\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for text_a, text_b, expected_type in examples:\n",
    "    score = verify(text_a, text_b)\n",
    "    print(f\"\\n{expected_type}:\")\n",
    "    print(f\"  A: {text_a}\")\n",
    "    print(f\"  B: {text_b}\")\n",
    "    print(f\"  Detected: {score.drift_type} (drift: {score.drift_score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Embedding Verification\n",
    "\n",
    "Compare vector embeddings directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmvk import verify_embeddings\n",
    "import numpy as np\n",
    "\n",
    "# Simulate embeddings from two models\n",
    "embedding_a = np.array([0.8, 0.2, 0.5, 0.3, 0.9])\n",
    "embedding_b = np.array([0.79, 0.21, 0.48, 0.31, 0.88])  # Slightly different\n",
    "embedding_c = np.array([0.1, 0.9, 0.2, 0.8, 0.1])       # Very different\n",
    "\n",
    "# Compare similar embeddings\n",
    "score_ab = verify_embeddings(embedding_a, embedding_b)\n",
    "print(\"üìä Similar Embeddings (A vs B)\")\n",
    "print(f\"   Drift: {score_ab.drift_score:.4f}\")\n",
    "print(f\"   Method: {score_ab.details.get('method', 'cosine')}\")\n",
    "\n",
    "# Compare different embeddings\n",
    "score_ac = verify_embeddings(embedding_a, embedding_c)\n",
    "print(f\"\\nüìä Different Embeddings (A vs C)\")\n",
    "print(f\"   Drift: {score_ac.drift_score:.4f}\")\n",
    "print(f\"   ‚ö†Ô∏è  Significant drift detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Distribution Verification\n",
    "\n",
    "Compare probability distributions (e.g., token probabilities):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmvk import verify_distributions\n",
    "import numpy as np\n",
    "\n",
    "# Simulate token probability distributions\n",
    "dist_a = np.array([0.7, 0.2, 0.1])  # High confidence in first token\n",
    "dist_b = np.array([0.65, 0.25, 0.1])  # Similar distribution\n",
    "dist_c = np.array([0.1, 0.2, 0.7])  # Very different!\n",
    "\n",
    "# Compare distributions using KL divergence\n",
    "score_ab = verify_distributions(dist_a, dist_b, method=\"kl\")\n",
    "print(\"üìä Similar Distributions (KL Divergence)\")\n",
    "print(f\"   Drift: {score_ab.drift_score:.4f}\")\n",
    "\n",
    "score_ac = verify_distributions(dist_a, dist_c, method=\"kl\")\n",
    "print(f\"\\nüìä Different Distributions (KL Divergence)\")\n",
    "print(f\"   Drift: {score_ac.drift_score:.4f}\")\n",
    "print(f\"   ‚ö†Ô∏è  Models disagree significantly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Multi-Model Consensus\n",
    "\n",
    "Verify agreement across multiple models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmvk import ConsensusVerifier\n",
    "\n",
    "# Simulate outputs from multiple models\n",
    "model_outputs = {\n",
    "    \"gpt-4\": \"The Great Wall of China is approximately 21,196 km long.\",\n",
    "    \"claude-3\": \"The Great Wall of China stretches about 21,196 kilometers.\",\n",
    "    \"gemini-pro\": \"The total length of the Great Wall is roughly 21,196 km.\",\n",
    "}\n",
    "\n",
    "# Create consensus verifier\n",
    "verifier = ConsensusVerifier(threshold=0.9)  # 90% agreement required\n",
    "\n",
    "# Verify consensus\n",
    "result = verifier.verify(model_outputs)\n",
    "\n",
    "print(\"üìä Multi-Model Consensus\")\n",
    "print(\"=\" * 60)\n",
    "for model, output in model_outputs.items():\n",
    "    print(f\"  {model}: {output[:50]}...\")\n",
    "\n",
    "print(f\"\\nüéØ Consensus Score: {result.consensus_score:.2%}\")\n",
    "print(f\"‚úÖ Consensus Reached: {result.consensus}\")\n",
    "if result.consensus:\n",
    "    print(f\"üìù Agreed Answer: {result.canonical_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with disagreement\n",
    "conflicting_outputs = {\n",
    "    \"gpt-4\": \"The population of Tokyo is 14 million.\",\n",
    "    \"claude-3\": \"Tokyo has a population of 37 million in the metro area.\",\n",
    "    \"gemini-pro\": \"About 13.96 million people live in Tokyo proper.\",\n",
    "}\n",
    "\n",
    "result = verifier.verify(conflicting_outputs)\n",
    "\n",
    "print(\"üìä Conflicting Outputs\")\n",
    "print(\"=\" * 60)\n",
    "for model, output in conflicting_outputs.items():\n",
    "    print(f\"  {model}: {output}\")\n",
    "\n",
    "print(f\"\\nüéØ Consensus Score: {result.consensus_score:.2%}\")\n",
    "print(f\"‚ùå Consensus Reached: {result.consensus}\")\n",
    "print(f\"\\n‚ö†Ô∏è  Models disagree! Pairwise drift scores:\")\n",
    "for pair, score in result.pairwise_scores.items():\n",
    "    print(f\"   {pair}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Batch Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmvk import verify_batch\n",
    "\n",
    "# Verify multiple pairs at once\n",
    "pairs = [\n",
    "    (\"2 + 2 = 4\", \"Two plus two equals four\"),\n",
    "    (\"Water boils at 100¬∞C\", \"Water boils at 212¬∞F\"),\n",
    "    (\"Python is a programming language\", \"Python is a type of snake\"),\n",
    "]\n",
    "\n",
    "results = verify_batch(pairs)\n",
    "\n",
    "print(\"üìä Batch Verification Results\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for (a, b), score in zip(pairs, results):\n",
    "    status = \"‚úÖ\" if score.drift_score < 0.5 else \"‚ö†Ô∏è\"\n",
    "    print(f\"\\n{status} Drift: {score.drift_score:.3f}\")\n",
    "    print(f\"   A: {a}\")\n",
    "    print(f\"   B: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Integrate with Agent OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_os import KernelSpace\n",
    "from cmvk import verify, ConsensusVerifier\n",
    "\n",
    "kernel = KernelSpace(policy=\"strict\")\n",
    "verifier = ConsensusVerifier(threshold=0.85)\n",
    "\n",
    "@kernel.register\n",
    "async def verified_agent(question: str):\n",
    "    \"\"\"\n",
    "    An agent that verifies answers across multiple models.\n",
    "    \"\"\"\n",
    "    # Simulate calling multiple models\n",
    "    # In production, these would be real API calls\n",
    "    outputs = {\n",
    "        \"model_1\": f\"Answer to '{question}': Response from model 1\",\n",
    "        \"model_2\": f\"Answer to '{question}': Response from model 1\",  # Same\n",
    "        \"model_3\": f\"Answer to '{question}': Response from model 1\",  # Same\n",
    "    }\n",
    "    \n",
    "    # Verify consensus\n",
    "    result = verifier.verify(outputs)\n",
    "    \n",
    "    if result.consensus:\n",
    "        return {\n",
    "            \"answer\": result.canonical_answer,\n",
    "            \"confidence\": result.consensus_score,\n",
    "            \"verified\": True\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"answer\": None,\n",
    "            \"confidence\": result.consensus_score,\n",
    "            \"verified\": False,\n",
    "            \"warning\": \"Models disagree - human review needed\"\n",
    "        }\n",
    "\n",
    "# Execute\n",
    "result = await kernel.execute(verified_agent, \"What is the speed of light?\")\n",
    "\n",
    "print(\"üìä Verified Agent Result\")\n",
    "print(\"=\" * 50)\n",
    "for k, v in result.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Automatic Hallucination Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmvk import HallucinationDetector\n",
    "\n",
    "# Create detector with thresholds\n",
    "detector = HallucinationDetector(\n",
    "    semantic_threshold=0.3,   # Flag if semantic drift > 30%\n",
    "    numerical_threshold=0.1,  # Flag if numerical drift > 10%\n",
    "    confidence_threshold=0.8  # Require 80% confidence\n",
    ")\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    (\"The Earth is 4.5 billion years old\", \"The Earth is 4.5 billion years old\"),\n",
    "    (\"The Earth is 4.5 billion years old\", \"The Earth is 6,000 years old\"),\n",
    "    (\"Water is H2O\", \"Water is composed of hydrogen and oxygen atoms\"),\n",
    "]\n",
    "\n",
    "print(\"üîç Hallucination Detection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for source, generated in test_cases:\n",
    "    result = detector.check(source_text=source, generated_text=generated)\n",
    "    \n",
    "    status = \"üö® HALLUCINATION\" if result.is_hallucination else \"‚úÖ OK\"\n",
    "    print(f\"\\n{status}\")\n",
    "    print(f\"   Source:    {source}\")\n",
    "    print(f\"   Generated: {generated}\")\n",
    "    if result.is_hallucination:\n",
    "        print(f\"   Reason: {result.reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Feature | What It Does |\n",
    "|---------|-------------|\n",
    "| `verify()` | Compare two texts for drift |\n",
    "| `verify_embeddings()` | Compare vector embeddings |\n",
    "| `verify_distributions()` | Compare probability distributions |\n",
    "| `ConsensusVerifier` | Multi-model agreement |\n",
    "| `verify_batch()` | Batch verification |\n",
    "| `HallucinationDetector` | Automatic hallucination flagging |\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "```python\n",
    "from cmvk import verify, ConsensusVerifier, HallucinationDetector\n",
    "\n",
    "# Basic verification\n",
    "score = verify(text_a, text_b)\n",
    "print(score.drift_score, score.drift_type)\n",
    "\n",
    "# Multi-model consensus\n",
    "verifier = ConsensusVerifier(threshold=0.9)\n",
    "result = verifier.verify({\"model1\": out1, \"model2\": out2})\n",
    "\n",
    "# Hallucination detection\n",
    "detector = HallucinationDetector(semantic_threshold=0.3)\n",
    "result = detector.check(source, generated)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [05-multi-agent-coordination](05-multi-agent-coordination.ipynb) - Trust between agents\n",
    "- [06-policy-engine](06-policy-engine.ipynb) - Deep dive into policies\n",
    "- [CMVK Documentation](https://github.com/imran-siddique/cmvk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
